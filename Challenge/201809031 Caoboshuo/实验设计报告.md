## 自主避障实验设计报告

本实验围绕智能驾驶环境感知的任务，完成行人目标识别展开。本实验基于JetBot的图像处理、检测与识别。在小车与设备在同一区域网上时，进行接下来的操作。

### 第一步：在JetBot上收集数据

在浏览器地址栏输入http://<jetbot_ip_address>:8888连接到小车，左侧打开Notebooks/collision_avoidance/。打开data_collection.ipynb文件。

显示实时摄像镜头。首先，让我们初始化并显示我们的相机，就像我们在远程操作笔记本中做的那样。我们的神经网络以一幅224x224像素的图像作为输入。我们将设置我们的相机的大小，以最小化我们的数据集的文件大小(我们已经测试，它为他的任务工作)，在一些场景中，它可能会更好地收集数据在一个更大的图像大小和缩小到所需的大小之后。

```python

import traitlets
import ipywidgets.widgets as widgets
from IPython.display import display
from jetbot import Camera, bgr8_to_jpeg

camera = Camera.instance(width=224, height=224)

image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera

camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)

display(image)

```
界面如图所示：

![markdown](https://i0.hdslb.com/bfs/album/44c2a42e14238edd074db68049564fe02c59a462.png@518w.png)

接下来让我们创建几个目录来存储我们所有的数据。我们将创建一个文件夹数据集，将包含两个子文件夹空闲和阻塞，我们将放置每个场景的图像。

```python
import os

blocked_dir = 'dataset/blocked'
free_dir = 'dataset/free'

we have this "try/except" statement because these next functions can throw an error if the directories exist already
try:
    os.makedirs(free_dir)
    os.makedirs(blocked_dir)
except FileExistsError:
print('Directories not created becasue they already exist')
```
如果你刷新左边的Jupyter文件浏览器，你现在应该会看到这些目录出现了。接下来，让我们创建并显示一些按钮，我们将使用这些按钮为每个类标签保存快照。我们还将添加一些文本框，显示到目前为止我们收集到的每个类别的图像数量。这很有用，因为我们要确保收集到的免费图像与被拦截的图像一样多。它还有助于了解我们总共收集了多少图像

```python
button_layout = widgets.Layout(width='128px', height='64px')
free_button = widgets.Button(description='add free', button_style='success', layout=button_layout)
blocked_button = widgets.Button(description='add blocked', button_style='danger', layout=button_layout)
free_count = widgets.IntText(layout=button_layout, value=len(os.listdir(free_dir)))
blocked_count = widgets.IntText(layout=button_layout, value=len(os.listdir(blocked_dir)))

display(widgets.HBox([free_count, free_button]))
display(widgets.HBox([blocked_count, blocked_button]))

```

现在，这些按钮没有任何作用。我们必须附加功能，以保存每个类别的图像到按钮的单击事件。我们将保存图像小部件的值(而不是相机)，因为它已经在压缩的JPEG格式!为了确保不会重复任何文件名(即使跨不同的machn)，我们将使用python中的uid包，它定义了uuid1方法来生成unque标识。这个唯一标识符是由诸如当前时间和计算机地址之类的信息生成的。

```python
from uuid import uuid1

def save_snapshot(directory):
    image_path = os.path.join(directory, str(uuid1()) + '.jpg')
    with open(image_path, 'wb') as f:
        f.write(image.value)

def save_free():
    global free_dir, free_count
    save_snapshot(free_dir)
    free_count.value = len(os.listdir(free_dir))
    
def save_blocked():
    global blocked_dir, blocked_count
    save_snapshot(blocked_dir)
    blocked_count.value = len(os.listdir(blocked_dir))
    
# attach the callbacks, we use a 'lambda' function to ignore the
# parameter that the on_click event would provide to our function
# because we don't need it.
free_button.on_click(lambda x: save_free())
blocked_button.on_click(lambda x: save_blocked())

```

现在上面的按钮应该将图像保存到空闲和被阻塞的目录。你可以使用Jupyter实验室文件浏览器来查看这些文件!现在开始收集一些数据吧1. 把机器人放在它被阻塞的场景中，然后按下添加阻塞2. 把机器人放在一个场景，它是免费的，并按下添加免费3.重复1、2。

这里有一些关于标签数据的提示1. 尝试不同的方向2. 尝试不同的照明3.尝试不同的物体/碰撞类型;墙壁,岩架,对象4. 尝试不同的纹理地板/物体;有图案、光滑、玻璃等最终，我们拥有的机器人在现实世界中遇到的场景的数据越多，我们的避碰行为就会越好。获得不同的数据是很重要的(正如上面的技巧所描述的)，不仅需要大量的da，而且你可能需要至少100张每个类的图像(这不是一门科学，在这里只是一个有用的技巧)。但别担心，一旦你开始行动，一切都会进展得很快:)

界面如图所示：

![markdown](https://i0.hdslb.com/bfs/album/4d61f05b737b453857e6c74cd6f283059378c286.png@518w.png)


```python
display(image)
display(widgets.HBox([free_count, free_button]))
display(widgets.HBox([blocked_count, blocked_button]))
```

### 第二步：训练神经网络

一旦你收集了足够的数据，我们需要将这些数据复制到GPU桌面或云机器上进行训练。首先，我们可以按终端命令将我们的数据集文件夹压缩成一个zip文件。

!zip -r -q dataset.zip dataset

此处如果已经有了刚刚压缩的dataset.zip文件，则不需要再运行此语句进行解压，否则会提示是否覆盖已存在的文件
程序运行到此处会下载alexnet模型，下载时间有点长。下载程序后/home/hetbot/.torch/models目录下会出现一个alexnet-owt-4df8aa71.pth文件。

最后运行程序训练神经网络，运行时间比较长。训练完成后，当前目录下会出现一个best_mode.pth文件。

### 第三步：自动避障

运行程序后会显示摄像头实时图像和一条滑条。互调表示遇到障碍物的概率，0.00表示前方没有障碍物，1.00表示前方哟障碍物需要转向避让。
此处适当调小一点速度，避免速度太快直接撞上障碍物。如果部分地方不能实现避障建议采集更多的数据。

【注意】部分语句运行时间可能比较长，JupyterLab右上角有程序运行提示标志。当小圆点为黑色时表示程序正在运行，白色表示空闲状态。

实验结果如图：

![markdown](https://i0.hdslb.com/bfs/album/b614b3ab2428e8d728176326d0e2dd2ad70f082e.png)


### 分析：
	实验中遇到的问题：
    
	在JetBot中，摄像头无法识别
	小车在所在地面上不能很好的运行。
	小车速度过快，在撞到障碍物后才能反应过来。
	实验的使用工具分析：
	使用了安装的工具安装小车
	通过电脑登录JetBot平台

### 总结：

    这个实验是通过在JetBot中运行相应文件的代码，通过使用摄像头收集图像数据，存为标签，分为阻塞和可通过的两类，当收集了足够的数据后，我们可以将其放在云平台上进行训练，最后进行训练神经网络，运行程序后，进行适当的配速，显示出摄像头实时图像和画像，当小车遇到障碍物时，完成自主避障实验。

### 心得体会：

	通过这个实验学习到了如何手动安装小车，提高了安装硬件的能力，在安装小车的过程中，分析了小车的组成元件，了解了小车的组成以及其内在的运行原理，体会到了安装小车过程中的困难与安装成功后的乐趣，比如小车的配件组成安装的组装过程中，将显卡放在了外面，为此有将显卡移动到内部重新安装了一遍。在JetBot上运行时，了解了软件端如何操控小车进行识别行人目标，在自动运行时进行自主避障。
