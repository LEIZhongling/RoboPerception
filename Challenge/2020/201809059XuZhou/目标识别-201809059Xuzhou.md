# 目标识别
`基于openvino进行对车辆的目标识别`

## 简述
目标识别是指一个特殊目标（或一种类型的目标）从其它目标（或其它类型的目标）中被区分出来的过程。它既包括两个非常相似目标的识别，也包括一种类型的目标同其他类型目标的识别。对于机器学习来说，主流有ＹＯＬＯ卷积神经网络和SSD神经网络，本次设计便是根据openvino提供的模型基于SSD网络模型进行的车辆识别。

## SSD网络模型简介

**SSD网络结构**：
<img src="http://s67.555889.xyz/2020/12/29/a9d47c32d8ecc36420c871fa7c9a1174.png" alt="a9d47c32d8ecc36420c871fa7c9a1174.png" border="0" />

**主要优点**：

- 在不同尺度的特征图，直接提取预设数目default box,进行预测
- 提高检测精度（尤其在小目标有提升)

**损失函数**:

SSD的损失函数定义为位置误差（locatization loss， loc）与置信度误差（confidence loss, conf）的加权和，其中N是先验框的正样本数量。c为类别置信度预测值。l 为先验框的所对应边界框的位置预测值，而g是ground truth的位置参数。权重系数α通过交叉验证设置为1。 
<img src="https://img-blog.csdnimg.cn/20190228144227321.png"/>
其中位置误差（仅针对正样本进行计算 ）: <img src="https://img-blog.csdnimg.cn/2019022815021341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzY4MjQ3,size_16,color_FFFFFF,t_70"/>
和置信度（误差包含两个部分：正样本的误差和负样本的误差）:<img src="https://img-blog.csdnimg.cn/2019022815021341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzY4MjQ3,size_16,color_FFFFFF,t_70"/>

**SSD数据加强**：
- SSD算法使用了多种数据增强的方法，包括水平翻转、裁剪、放大和缩小等。论文明确指出，数据增强可以明显的提高算法的性能。主要的目的是为了使得该算法对输入的不同大小和不同形状的目标具有更好的鲁棒性。直观的理解是通过这个数据增强操作可以增加训练样本的个数，同时构造出更多的不同形状和大小的目标，将其输入到网络中，可以使得网络学习到更加鲁棒的特征。 
**NMS(非大值抑制)**：
-  SSD 算法中，NMS 至关重要。因为多个 feature map 最后会产生大量的 bounding boxes，即最终检测结果。然而在这些bounding boxes中存在着大量的错误的、重叠的、不准确的样本，这不仅造成了巨大的计算量，如果处理不好会影响算法的性能。
**预测过程**:
- 预测过程比较简单，对于每个预测框(default boxes)，首先根据类别置信度确定其类别（置信度最大者）与置信度值，并过滤掉属于背景的预测框。然后根据置信度阈值（如0.5）过滤掉阈值较低的预测框。对于留下的预测框进行解码，根据先验框得到其真实的位置参数，一般需要根据置信度进行降序排列，然后仅保留top-k（如400）个预测框。最后就是进行NMS算法，过滤掉那些重叠度较大的预测框。最后剩余的预测框就是检测结果了。 

## 实验操作
**openvino安装**

- 进入官网下载对应版本的openvino

<img src="http://s68.555889.xyz/2020/12/30/2624e2bb2abfccda484dbc127c80163c.png" alt="openvino下载选择" border="0">

- 填写下载信息
  <img src="http://s69.555889.xyz/2020/12/30/0d04eb1f4fb259f46109f08dd9a1ab19.png" alt="openvino下载选择2" border="0">

- 下载后安装openvino
  <img src="http://s66.555889.xyz/2020/12/30/bd17dbb95795153b849eed6a8bd0db53.png" alt="安装openvino" border="0">

- 安装cmake
  <img src="http://s67.555889.xyz/2020/12/30/e375e4578b2a95ab8834f04a98e02c6a.png" alt="cmake安装" border="0">

- 安装python3.6.5
  <img src="http://s61.555889.xyz/2020/12/30/a2bd962b89ad108f34b36ab83a09e42e.png" alt="python3.6.5安装" border="0">

**openvino的安装验证**

- 进入中断，并打开相应目录，运行初始化文件
  <img src="http://s67.555889.xyz/2020/12/30/340a7f8d5f45f29c9f033d2fe1b24ec7.png" alt="openvino环境初始化" border="0">

- 进入"C:\Program Files (x86)\IntelSWTools\openvino_2020.1.033\deployment_tools\demo"目录并运行相应文件
  <img src="http://s67.555889.xyz/2020/12/30/340a7f8d5f45f29c9f033d2fe1b24ec7.png" alt="openvino环境初始化" border="0">
  <center>验证通过</center>
**运行编译**
- 进入build_demo_msvc.bat的目录
  <img src="http://s69.555889.xyz/2020/12/30/02042d70791bf237e2ef2d05f8c79da1.png" alt="编译运行文件路径" border="0">
- 编译运行文件
 <img src="http://s68.555889.xyz/2020/12/30/e1dd49e45e7a3d8350a42cf6ea7c1243.png" alt="编译运行文件" border="0">
- 进入生成EXE文件的项目
  <img src="http://s64.555889.xyz/2020/12/30/61bcde55bc7a92b2635430d341935a6e.png" alt="生成EXE项目的路径" border="0">
- 生成EXE文件
<img src="http://s63.555889.xyz/2020/12/30/5dba17412c0c5feaa00a80b21afb6bda.png" alt="生成EXE" border="0">
  

**模型下载**：
- 下载模型相关文件
  <img src="http://s62.555889.xyz/2020/12/30/83959ae98f4a3b40d485de265ac24277.png" alt="模型下载准备" border="0">
- 下载对应的object_detection_sample_ssd_asyn.py模型
  <img src="http://s68.555889.xyz/2020/12/30/4a88a261408e4c0fed03b706a2efbe09.png" alt="模型下载" border="0">
- 最终路径
  <img src="http://s67.555889.xyz/2020/12/30/ff711ab5f1d3020fff8b63a137cde87b.png" alt="模型路径" border="0">
  `其中bin文件保存权重数据，xml保存网络拓扑架构`
**素材下载**：
- 进入网站下载素材（mp4）
 <img src="http://s65.555889.xyz/2020/12/30/e046b36a6b79ca41cb8821e028e45baf.png" alt="素材下载" border="0">
 
 **结果展示**：
- 运行object_detection_sample_ssd_asyn.exe和对应的预训练模型即可得出结果
 <img src="http://s66.555889.xyz/2020/12/30/35fc6d793bc53ab5ab56d7b3dfd7c489.png" alt="执行命令" border="0">
 - 结果
<img src="http://s61.555889.xyz/2020/12/30/6b06e5ccf9c322f0edfc8497de8b8f0f.png" alt="结果L" border="0">
<img src="http://s62.555889.xyz/2020/12/30/c3c5f2687c1e70e88e1cb4ef848c3e7b.gif" alt="c3c5f2687c1e70e88e1cb4ef848c3e7b.gif" border="0" />

**代码分析**：
 -  代码位置（使用VS 2019查看）
  <img src="http://s61.555889.xyz/2020/12/30/47db5af472e88dbf8bc79362b00d0ea1.png" alt="47db5af472e88dbf8bc79362b00d0ea1.png" border="0" />
```C++
//将包含文件引入
#include <gflags/gflags.h>

#include <chrono>
#include <iostream>
#include <memory>
#include <vector>
#include <string>
#include <algorithm>

#include <inference_engine.hpp>

#include <monitors/presenter.h>
#include <samples/ocv_common.hpp>
#include <samples/slog.hpp>

#include "object_detection_demo_ssd_async.hpp"
#ifdef WITH_EXTENSIONS
#include <ext_list.hpp>
#endif
//使用openvino的命名空间
using namespace InferenceEngine;

bool ParseAndCheckCommandLine(int argc, char *argv[]) { 
    //  解析和验证输入参数
    gflags::ParseCommandLineNonHelpFlags(&argc, &argv, true);
    if (FLAGS_h) {
       showUsage();
       showAvailableDevices();
       return false;
    }
    slog::info << "Parsing input parameters" << slog::endl;

    if (FLAGS_i.empty()) {
        throw std::logic_error("Parameter -i is not set");
    }

    if (FLAGS_m.empty()) {
        throw std::logic_error("Parameter -m is not set");
    }

    return true;
}

void frameToBlob(const cv::Mat& frame,
                 InferRequest::Ptr& inferRequest,
                 const std::string& inputName) {
                     //图像转换
    if (FLAGS_auto_resize) {
        /* 设置包含读取图像的输入blob。调整大小和布局转换*/
        inferRequest->SetBlob(inputName, wrapMat2Blob(frame));
    } else {
        /* 调整图像的大小并将数据复制到输入blob中 */
        Blob::Ptr frameBlob = inferRequest->GetBlob(inputName);
        matU8ToBlob<uint8_t>(frame, frameBlob);
    }
}

int main(int argc, char *argv[]) {
    try {
        //推理信息显示
        std::cout << "InferenceEngine: " << GetInferenceEngineVersion() << std::endl;

        //解析和验证输入参数
        if (!ParseAndCheckCommandLine(argc, argv)) {
            return 0;
        }

        slog::info << "Reading input" << slog::endl;

        cv::VideoCapture cap;//建立视频对象
        if (!((FLAGS_i == "cam") ? cap.open(0) : cap.open(FLAGS_i.c_str()))) {
            throw std::logic_error("Cannot open input file or camera: " + FLAGS_i);
        }//异常检测

        const size_t width  = (size_t) cap.get(cv::CAP_PROP_FRAME_WIDTH);
        const size_t height = (size_t) cap.get(cv::CAP_PROP_FRAME_HEIGHT);

        // 读取视频文件
        cv::Mat curr_frame;  cap >> curr_frame;
        cv::Mat next_frame;

        if (!cap.grab()) {
            throw std::logic_error("This demo supports only video (or camera) inputs !!! "
                                   "Failed getting next frame from the " + FLAGS_i);
        }//输入错误提示
         

        // 推理开始
        slog::info << "Loading Inference Engine" << slog::endl;
        Core ie;

        slog::info << "Device info: " << slog::endl;
        std::cout << ie.GetVersions(FLAGS_d);

        /**1.加载插件的扩展**/

#ifdef WITH_EXTENSIONS
        /**加载默认的扩展 **/
        if (FLAGS_d.find("CPU") != std::string::npos) {
            ie.AddExtension(std::make_shared<Extensions::Cpu::CpuExtensions>(), "CPU");
        }
#endif

        if (!FLAGS_l.empty()) {
            // CPU(MKLDNN)扩展作为共享库加载，并作为基扩展的指针传递
            IExtensionPtr extension_ptr = make_so_pointer<IExtension>(FLAGS_l.c_str());
            ie.AddExtension(extension_ptr, "CPU");
        }
        if (!FLAGS_c.empty()) {
            //clDNN扩展从xml描述和OpenCL内核文件中加载
            ie.SetConfig({{PluginConfigParams::KEY_CONFIG_FILE, FLAGS_c}}, "GPU");
        }

        /** 每层指标 **/
        if (FLAGS_pc) {
            ie.SetConfig({ { PluginConfigParams::KEY_PERF_COUNT, PluginConfigParams::YES } });
        }
         

        //   2.读取由ModelOptimizer生成的IR (.xml and .bin 文件) 
        slog::info << "Loading network files" << slog::endl;
        /** 读取网络模型**/
        auto cnnNetwork = ie.ReadNetwork(FLAGS_m);
        /** 设置训练批量 **/
        slog::info << "Batch size is forced to  1." << slog::endl;
        cnnNetwork.setBatchSize(1);
        /** 读取层数**/
        std::string labelFileName = fileNameNoExt(FLAGS_m) + ".labels";
        std::vector<std::string> labels;
        std::ifstream inputFile(labelFileName);
        std::copy(std::istream_iterator<std::string>(inputFile),
                  std::istream_iterator<std::string>(),
                  std::back_inserter(labels));
         

        /** 基于ssd的网络应该有一个输入和一个输出 **/
        //   3. 配置输入输出  
        // 准备输入blob  
        slog::info << "Checking that the inputs are as the demo expects" << slog::endl;
        InputsDataMap inputInfo(cnnNetwork.getInputsInfo());//读入神经网络

        std::string imageInputName, imageInfoInputName;
        size_t netInputHeight, netInputWidth;
        //对输入图像的处理
        for (const auto & inputInfoItem : inputInfo) {
            if (inputInfoItem.second->getTensorDesc().getDims().size() == 4) {  //第一次输入包含图像
                imageInputName = inputInfoItem.first;
                inputInfoItem.second->setPrecision(Precision::U8);
                if (FLAGS_auto_resize) {
                    inputInfoItem.second->getPreProcess().setResizeAlgorithm(ResizeAlgorithm::RESIZE_BILINEAR);
                    inputInfoItem.second->getInputData()->setLayout(Layout::NHWC);
                } else {
                    inputInfoItem.second->getInputData()->setLayout(Layout::NCHW);
                }
                const TensorDesc& inputDesc = inputInfoItem.second->getTensorDesc();
                netInputHeight = getTensorHeight(inputDesc);
                netInputWidth = getTensorWidth(inputDesc);
            } else if (inputInfoItem.second->getTensorDesc().getDims().size() == 2) {  // 第二次输入包含图像
                imageInfoInputName = inputInfoItem.first;
                inputInfoItem.second->setPrecision(Precision::FP32);
            } else {
                throw std::logic_error("Unsupported " +
                                       std::to_string(inputInfoItem.second->getTensorDesc().getDims().size()) + "D "
                                       "input layer '" + inputInfoItem.first + "'. "
                                       "Only 2D and 4D input layers are supported");
            }
        }

        // 输出 blobs 
        slog::info << "Checking that the outputs are as the demo expects" << slog::endl;
        OutputsDataMap outputInfo(cnnNetwork.getOutputsInfo());
        if (outputInfo.size() != 1) {
            throw std::logic_error("This demo accepts networks having only one output");
        }
        DataPtr& output = outputInfo.begin()->second;
        auto outputName = outputInfo.begin()->first;
        const int num_classes = cnnNetwork.getLayerByName(outputName.c_str())->GetParamAsInt("num_classes");
        if (static_cast<int>(labels.size()) != num_classes) {
            if (static_cast<int>(labels.size()) == (num_classes - 1))   
                labels.insert(labels.begin(), "fake");
            else
                labels.clear();
        }
        const SizeVector outputDims = output->getTensorDesc().getDims();
        const int maxProposalCount = outputDims[2];
        const int objectSize = outputDims[3];
        if (objectSize != 7) {
            throw std::logic_error("Output should have 7 as a last dimension");
        }
        if (outputDims.size() != 4) {
            throw std::logic_error("Incorrect output dimensions for SSD");
        }
        output->setPrecision(Precision::FP32);
        output->setLayout(Layout::NCHW);
        

        //  4. 模型加载
        slog::info << "Loading model to the device" << slog::endl;
        ExecutableNetwork network = ie.LoadNetwork(cnnNetwork, FLAGS_d);
         

        //   5.创建推断请求 
        InferRequest::Ptr async_infer_request_curr = network.CreateInferRequestPtr();
        InferRequest::Ptr async_infer_request_next = network.CreateInferRequestPtr();

        /* 只设置一次图像信息输入(如果在模型中使用)就足够了*/
        if (!imageInfoInputName.empty()) {
            auto setImgInfoBlob = [&](const InferRequest::Ptr &inferReq) {
                auto blob = inferReq->GetBlob(imageInfoInputName);
                auto data = blob->buffer().as<PrecisionTrait<Precision::FP32>::value_type *>();
                data[0] = static_cast<float>(netInputHeight);  //高
                data[1] = static_cast<float>(netInputWidth);  // 宽
                data[2] = 1;
            };
            setImgInfoBlob(async_infer_request_curr);
            setImgInfoBlob(async_infer_request_next);
        }
      

        //   6. 推理 
        slog::info << "Start inference " << slog::endl;

        bool isLastFrame = false;
        bool isAsyncMode = false;  // 执行同步模式启动
        bool isModeChanged = false;  // 当执行模式改变时设置为真 (SYNC<->ASYNC)

        typedef std::chrono::duration<double, std::ratio<1, 1000>> ms;
        auto total_t0 = std::chrono::high_resolution_clock::now();
        auto wallclock = std::chrono::high_resolution_clock::now();
        double ocv_decode_time = 0, ocv_render_time = 0;

        std::cout << "To close the application, press 'CTRL+C' here or switch to the output window and press ESC key" << std::endl;
        std::cout << "To switch between sync/async modes, press TAB key in the output window" << std::endl;
        cv::Size graphSize{static_cast<int>(cap.get(cv::CAP_PROP_FRAME_WIDTH) / 4), 60};
        Presenter presenter(FLAGS_u, static_cast<int>(cap.get(cv::CAP_PROP_FRAME_HEIGHT)) - graphSize.height - 10, graphSize);
        while (true) {
            auto t0 = std::chrono::high_resolution_clock::now();
            //这里是第一个异步点:
            // 在异步模式下，我们捕获帧来填充下一个请求
            // 在常规模式下，我们捕获当前推断请求的帧
            if (!cap.read(next_frame)) {
                if (next_frame.empty()) {
                    isLastFrame = true;  // 停止视频捕获
                } else {
                    throw std::logic_error("Failed to get frame from cv::VideoCapture");
                }
            }
            if (isAsyncMode) {
                if (isModeChanged) {
                    frameToBlob(curr_frame, async_infer_request_curr, imageInputName);
                }
                if (!isLastFrame) {
                    frameToBlob(next_frame, async_infer_request_next, imageInputName);
                }
            } else if (!isModeChanged) {
                frameToBlob(curr_frame, async_infer_request_curr, imageInputName);
            }

            auto t1 = std::chrono::high_resolution_clock::now();
            ocv_decode_time = std::chrono::duration_cast<ms>(t1 - t0).count();

            t0 = std::chrono::high_resolution_clock::now();
            // 主要同步点:
            // 在真正的异步模式中，我们开始下一个请求，同时等待当前请求完成
            // 在常规模式下，我们启动当前请求并立即等待它完成
            if (isAsyncMode) {
                if (isModeChanged) {
                    async_infer_request_curr->StartAsync();
                }
                if (!isLastFrame) {
                    async_infer_request_next->StartAsync();
                }
            } else if (!isModeChanged) {
                async_infer_request_curr->StartAsync();
            }

            if (OK == async_infer_request_curr->Wait(IInferRequest::WaitMode::RESULT_READY)) {
                t1 = std::chrono::high_resolution_clock::now();
                ms detection = std::chrono::duration_cast<ms>(t1 - t0);

                t0 = std::chrono::high_resolution_clock::now();
                ms wall = std::chrono::duration_cast<ms>(t0 - wallclock);
                wallclock = t0;

                t0 = std::chrono::high_resolution_clock::now();

                presenter.drawGraphs(curr_frame);

                std::ostringstream out;
                out << "OpenCV cap/render time: " << std::fixed << std::setprecision(2)
                    << (ocv_decode_time + ocv_render_time) << " ms";
                cv::putText(curr_frame, out.str(), cv::Point2f(0, 25), cv::FONT_HERSHEY_TRIPLEX, 0.6, cv::Scalar(0, 255, 0));
                out.str("");
                out << "Wallclock time " << (isAsyncMode ? "(TRUE ASYNC):      " : "(SYNC, press Tab): ");
                out << std::fixed << std::setprecision(2) << wall.count() << " ms (" << 1000.f / wall.count() << " fps)";
                cv::putText(curr_frame, out.str(), cv::Point2f(0, 50), cv::FONT_HERSHEY_TRIPLEX, 0.6, cv::Scalar(0, 0, 255));
                if (!isAsyncMode) {  // 在真正的异步模式下，没有办法直接测量检测时间
                    out.str("");
                    out << "Detection time  : " << std::fixed << std::setprecision(2) << detection.count()
                        << " ms ("
                        << 1000.f / detection.count() << " fps)";
                    cv::putText(curr_frame, out.str(), cv::Point2f(0, 75), cv::FONT_HERSHEY_TRIPLEX, 0.6,
                                cv::Scalar(255, 0, 0));
                }

                // 输出blobs 
                // 处理当前请求的结果
                const float *detections = async_infer_request_curr->GetBlob(outputName)->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();
                for (int i = 0; i < maxProposalCount; i++) {
                    float image_id = detections[i * objectSize + 0];
                    if (image_id < 0) {
                        break;
                    }

                    float confidence = detections[i * objectSize + 2];
                    auto label = static_cast<int>(detections[i * objectSize + 1]);
                    float xmin = detections[i * objectSize + 3] * width;
                    float ymin = detections[i * objectSize + 4] * height;
                    float xmax = detections[i * objectSize + 5] * width;
                    float ymax = detections[i * objectSize + 6] * height;

                    if (FLAGS_r) {
                        std::cout << "[" << i << "," << label << "] element, prob = " << confidence <<
                                  "    (" << xmin << "," << ymin << ")-(" << xmax << "," << ymax << ")"
                                  << ((confidence > FLAGS_t) ? " WILL BE RENDERED!" : "") << std::endl;
                    }

                    if (confidence > FLAGS_t) {
                       //概率计算
                        std::ostringstream conf;
                        conf << ":" << std::fixed << std::setprecision(3) << confidence;
                        cv::putText(curr_frame,
                                    (static_cast<size_t>(label) < labels.size() ?
                                    labels[label] : std::string("label #") + std::to_string(label)) + conf.str(),
                                    cv::Point2f(xmin, ymin - 5), cv::FONT_HERSHEY_COMPLEX_SMALL, 1,
                                    cv::Scalar(0, 0, 255));
                        cv::rectangle(curr_frame, cv::Point2f(xmin, ymin), cv::Point2f(xmax, ymax), cv::Scalar(0, 0, 255));
                    }
                }
            }

            if (!FLAGS_no_show) {
                cv::imshow("Detection results", curr_frame);
            }

            t1 = std::chrono::high_resolution_clock::now();
            ocv_render_time = std::chrono::duration_cast<ms>(t1 - t0).count();

            if (isLastFrame) {
                break;
            }

            if (isModeChanged) {
                isModeChanged = false;
            }

            // 最后一点
            //  将当前请求为下一次迭代交换
            curr_frame = next_frame;
            next_frame = cv::Mat();
            if (isAsyncMode) {
                async_infer_request_curr.swap(async_infer_request_next);
            }

            const int key = cv::waitKey(1);
            if (27 == key)  // 退出
                break;
            if (9 == key) {  // 标记
                isAsyncMode ^= true;
                isModeChanged = true;
            } else {
                presenter.handleKey(key);
            }
        }
        
        auto total_t1 = std::chrono::high_resolution_clock::now();
        ms total = std::chrono::duration_cast<ms>(total_t1 - total_t0);
        std::cout << "Total Inference time: " << total.count() << std::endl;

        /** 结果展示**/
        if (FLAGS_pc) {
            printPerformanceCounts(*async_infer_request_curr, std::cout, getFullDeviceName(ie, FLAGS_d));
        }
        std::cout << presenter.reportMeans() << '\n';
    }
    //异常捕获
    catch (const std::exception& error) {
        std::cerr << "[ ERROR ] " << error.what() << std::endl;
        return 1;
    }
    catch (...) {
        std::cerr << "[ ERROR ] Unknown/internal exception happened." << std::endl;
        return 1;
    }

    slog::info << "Execution successful" << slog::endl;
    return 0;
}

```
- 小结

     - 本代码内容主要是加载SSD的模型进行目标的识别，通过Opencv进行视频的裁剪出每一帧图片，并将参数加载至模型中进行识别。
  
**总结**：
本次实验利用SSD模型实现端对端车辆检测，其中车辆的颜色，形状各异速度也不同，本模型都能进行识别，但在某些条件下（车辆过小，车辆显示不完整的）本模型还是识别不了，出现了欠拟合的情况。
**心得**：
通过本次实验，我学习到了在Windows和linux系统（系统崩溃过，故实验采用windows系统）下使用openvino，并知道对模型转换和调用，以及vs2019对代码的编译运行。在机器学习上，我学到了YOLO以及SSD这两大 主流的目标识别模型，并选择了SSD模型进行目标检测实验，对SSD模型有了更加深入的理解，在此基础上理解了C++代码，并清楚各功能模块的作用和对所学的知识有着更加深入的理解。

- linux运行示例图
<img src="http://s61.555889.xyz/2020/12/30/9d417040472dc969da9ceace58ead3c9.jpg" alt="9d417040472dc969da9ceace58ead3c9.jpg" border="0" />
