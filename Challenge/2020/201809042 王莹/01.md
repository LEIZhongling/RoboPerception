>>>> ## 基于opencv的图像处理、检测与识别
## 基于opencv的车道线检测
### 准备工作：VS2019与OpenCV4.11的详细配置
1、安装vs2019 Community。
下载地址https://visualstudio.microsoft.com/：
[![rbtlAe.png](https://s3.ax1x.com/2020/12/29/rbtlAe.png)](https://imgchr.com/i/rbtlAe)
安装后打开，启动界面如下：
[![rbtBNQ.png](https://s3.ax1x.com/2020/12/29/rbtBNQ.png)](https://imgchr.com/i/rbtBNQ)
2、安装OpenCV 4.1.1版本
从www.opencv.org下载，并安装到某个给定目录下（路径无中文），如下：
[![rbthEF.png](https://s3.ax1x.com/2020/12/29/rbthEF.png)](https://imgchr.com/i/rbthEF)
3、配置OpenCV环境变量
在我的电脑上右键“属性”，点击“高级系统环境”，
[![rbNCvt.png](https://s3.ax1x.com/2020/12/29/rbNCvt.png)](https://imgchr.com/i/rbNCvt)
在用户变量中，点击Path变量并编辑，添加dll所在路径
[![rbNu2n.png](https://s3.ax1x.com/2020/12/29/rbNu2n.png)](https://imgchr.com/i/rbNu2n)
[![rbN8VU.png](https://s3.ax1x.com/2020/12/29/rbN8VU.png)](https://imgchr.com/i/rbN8VU)
确定后，并重启以使得环境变量生效。

4、在vs 2019中新建项目
选择路径“File->New->Project”：
[![rbNBqK.png](https://s3.ax1x.com/2020/12/29/rbNBqK.png)](https://imgchr.com/i/rbNBqK)
依次选择Language为C++，Platform为Windows，Project type为desktop,
[![rbNfMt.png](https://s3.ax1x.com/2020/12/29/rbNfMt.png)](https://imgchr.com/i/rbNfMt)
选择Windows Desktop Wizard，并选择Next,
[![rbNbGj.png](https://s3.ax1x.com/2020/12/29/rbNbGj.png)](https://imgchr.com/i/rbNbGj)
点击Create,并下弹出的对话框中选择，Application type 为Console, 选择Empty Project,
[![rbNqRs.png](https://s3.ax1x.com/2020/12/29/rbNqRs.png)](https://imgchr.com/i/rbNqRs)
点击OK，在Source files里面右键，添加New item:
[![rbUpoF.png](https://s3.ax1x.com/2020/12/29/rbUpoF.png)](https://imgchr.com/i/rbUpoF)
添加test01.cpp源文件。

右键test01这个Project,选择Properties:
[![rbUAQ1.png](https://s3.ax1x.com/2020/12/29/rbUAQ1.png)](https://imgchr.com/i/rbUAQ1)
选择VC++ Directories，在Include Directories中，
[![rbUMJH.png](https://s3.ax1x.com/2020/12/29/rbUMJH.png)](https://imgchr.com/i/rbUMJH)
添加C:\Programs\OpenCV\opencv411\build\include和C:\Programs\OpenCV\opencv411\build\include\opencv2这两个目录。
[![rbU8yt.png](https://s3.ax1x.com/2020/12/29/rbU8yt.png)](https://imgchr.com/i/rbU8yt)在Library Directories中添加C:\Programs\OpenCV\opencv411\build\x64\vc15\lib：
[![rbUtw8.png](https://s3.ax1x.com/2020/12/29/rbUtw8.png)](https://imgchr.com/i/rbUtw8)
在Linker->Input目录下，点击Additional Dependencies并添加opencv_world411d.lib静态库：
[![rbUNTS.png](https://s3.ax1x.com/2020/12/29/rbUNTS.png)](https://imgchr.com/i/rbUNTS)
点击OK并确定退出。

5、测试OpenCV代码
在test01.cpp中添加以下代码：
```python
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;

int main()
{
	Mat img = imread("D:\\Works\\Data\\Bear\\001.jpg");

	imshow("test01", img);

	waitKey(0);
}

```
并编译执行,得到：
[![rbUI61.png](https://s3.ax1x.com/2020/12/29/rbUI61.png)](https://imgchr.com/i/rbUI61)
准备工作结束！！！
### 1.问题定义
车道线检测，就是在汽车行驶时通过汽车前方的摄像头捕捉到地面的图像（视频），通过Opencv对图片（视频）进行一系列处理后，可以在图片（视频）中标注出车道线，然后以此作为汽车自动驾驶时的安全行驶范围。由此可见车道线检测是无人驾驶中最为重要且基础的一环。在无人车自动行驶的过程中，实时获取路面视频流，然后对视频进行处理，标注出可行驶的路线。
### 2.实现原理
算法基本思想说明：
传统的车道线检测，多数是基于霍夫直线检测，其实这个里面有个很大的误区，霍夫直线拟合容易受到各种噪声干扰，直接运用有时候效果不好，更多的时候通过霍夫直线检测进行初步的筛选，然后再有针对性的进行直线拟合，根据拟合的直线四个点坐标，绘制出车道线，这种方式可以有效避免霍夫直线拟合不良后果，是一种更加稳定的车道线检测方法，在实际项目中，可以选择两种方法并行，在计算出结果后进行叠加或者对比提取，今天分享的案例主要是绕开了霍夫直线检测，通过对二值图像进行轮廓分析与几何分析，提取到相关的车道线信息、然后进行特定区域的像素扫描，拟合生成直线方程，确定四个点绘制出车道线，对连续的视频来说，如果某一帧无法正常检测，就可以通过缓存来替代绘制，从而实现在视频车道线检测中实时可靠。
### 3.算法设计
关于车道线检测，本次实验只是对图片进行处理，因此省去了不少步骤，本次实验主要参考了优达学院的无人驾驶工程师课程，这一系列课程简述了如何将图片的车道线进行检测并标注出来，之后调用pymovie将视频中的每一个目标视频，分割为一帧一帧的图片，然后针对每一个图片进行车道线的识别，最终将每一帧再合成为一个输出视频，整个课程不止针对简单的车道线，还考虑了在阴影条件下，在车道线有弯道时，以及车道线并不完整有部分车道线消失时依旧能够完成车道线的检测。本次实验就是在学习并研究以上课程中完成
    大体上整个识别的过程可以分为以下几个步骤：
1.加载图片，将其变为由RGB表示的数组
2.对图片进行灰度处理，并去除噪点
3.通过opencv自带函数实现边缘检测（sobel算子，canny算子，prewitt算子）
4.对检测后的图像裁剪出车道线
5.通过霍夫变换将车道线画出
6.将检测到车道线加载到原图像中
#### 3.1数据处理
首先加载原图片采取cv2.imread加载方式这里也可以采用 mpimg.read 的加载方式,但是跟前面相比颜色的排序由GBR变为RGB。之后应用时注意顺序的变化。
对于输入的图像，我们通过灰度处理将其从一个三通道的图像转换为单通道图像。具体过程就是RGB对应的不同权重的求和：
[![rHOimn.png](https://s3.ax1x.com/2020/12/29/rHOimn.png)](https://imgchr.com/i/rHOimn)

我们直接调用cvtColor（）函数完成这个过程，之后我们就要消除这个图像部分噪点，这样就可以避免在接下来的边缘检测时，在车道线附近出现某个噪点，而使最终的检测结果与真实值相比出现较大误差。
常用的去噪方法有均值模糊、中值模糊和高斯模糊我们在这里使用的是用高斯模糊并使用5*5的矩阵作为核心来对图片进行卷积运算。
[![rHOnl4.png](https://s3.ax1x.com/2020/12/29/rHOnl4.png)](https://imgchr.com/i/rHOnl4)

其中kernel size越大，对图片进行卷积运算的模板矩阵也就越大最后计算出来的结果也就越模糊，去掉的噪点也就越多。这样在之后的边缘检测中获得最终的图案越好，然而这对车道线检测时也会有少量的损失，但是这在之后的霍夫变换中可以对其进行弥补。（但是如果车道线在边缘检测中损失过多，可能会影响霍夫变换最终生成的直线。）
* 原始图像[![rHXC9O.png](https://s3.ax1x.com/2020/12/29/rHXC9O.png)](https://imgchr.com/i/rHXC9O) 
* 进行灰度处理
  [![rHXGbn.png](https://s3.ax1x.com/2020/12/29/rHXGbn.png)](https://imgchr.com/i/rHXGbn)
  
* 高斯模糊
  [![rHjCaq.png](https://s3.ax1x.com/2020/12/29/rHjCaq.png)](https://imgchr.com/i/rHjCaq)

* 高斯模糊去除大部分噪点（kernel=15）
[![rHvF0A.png](https://s3.ax1x.com/2020/12/29/rHvF0A.png)](https://imgchr.com/i/rHvF0A)


####3.2通过opencv中的各种滤波器进行边缘检测

边缘检测也就是对图像求导数的过程，图像的边缘也就是一阶导数出现极值点，或者二阶导数为零的情况。在opencv中有3种边缘检测算子，一阶导数Roberts、Sobel、Prewitt。二阶导数Laplacian、Log/Marr、(Kirsch、Nevitia)，非微分边缘检测算子：Canny。

通过以上算子，来对整个图像求解梯度，我们可以看出在Sobel图像中可以提取出明显的车道线边缘，以及汽车边缘，周围较为明显景物的边缘。Sobel算子对于灰度渐变和噪声较多的图像有着较好的处理效果，Sobel算子对于边缘定位比较准确。相比之下Reberts，Prewitt、Laplacian都是跟Sobel算子不同，针对的图像也不同，导致最后得到的效果不同，而Canny（）是内部使用了Sobel算子，对每个像素点计算出梯度强度和方向之后，通过应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。

* 高通滤波处理
[![rHv2cD.png](https://s3.ax1x.com/2020/12/29/rHv2cD.png)](https://imgchr.com/i/rHv2cD)

* Canny（low_threshold=50  high_threshold=200）
[![rHvH9f.png](https://s3.ax1x.com/2020/12/29/rHvH9f.png)](https://imgchr.com/i/rHvH9f)

*  Canny（low_threshold=100 high_threshold=200）
  [![rHxFvF.png](https://s3.ax1x.com/2020/12/29/rHxFvF.png)](https://imgchr.com/i/rHxFvF)

  Canny滤波器根据选择不同的low_threshold，最终获取的图像也是不同，这种方法可以把图片中距离较远，树木车俩等较为模糊的物体，最后的由于阈值取的较高而被抑制，最终图像也就不再包含其边缘。
  
#### 3.3 对边缘检测后的图像进行截取(获取到车道线的边缘即可)
通过上面的几个操作，我们可以看到车道线已经能够检测出来，然而仅靠Canny函数的阈值来调整图像，是无法获得单独的车道线的，当阈值调整至135，左侧车道线就会少一部分，但是左侧的边缘仍然无法消除。

这时我们可以考虑对该边缘线进行筛选，假设无人车上的 摄像头角度不变，那么在保证车辆行驶在规定车道线内的前提下，相对于车来说，前方的车道线的位置是固定的（直线）。左右两条车道线以相对的斜率，在前方的某点相交。（通过基于透视的图像矫正方法，可以将我们所看到的两条斜直线，转为两条相交直线）。 因此车道线多在图片的下面的三角区域之中，根据本图像的大小为（540，960），而我们的图像是一个二维数组，通过标定一个区域
将所有该区域内的车道线边缘检测结果保留，其他的令其像素点值为0。整个过程为将标定的范围标为mask（初始为与原图像shape相同的全0数组），将该区域内标为255，然后将mask与原图像进行与操作，这样就可以只保留下区域内的结果。其他区域像素点值变为0，也就变成纯黑色。

* 在matplotlib中可以标注出规定区域范围
[![rbCHCn.png](https://s3.ax1x.com/2020/12/29/rbCHCn.png)](https://imgchr.com/i/rbCHCn)

*  图像中只保留下了最后的车道线
 [![rbCXuT.png](https://s3.ax1x.com/2020/12/29/rbCXuT.png)](https://imgchr.com/i/rbCXuT)

 #### 3.4 通过霍夫变换车道线进行补全并绘制至原图像中

在将图像进行截取之后，据我们想要的最终结果已经很接近了，然而由于有的车道线是虚线形式的，我们所获得的图像也就会成为类似矩形的分段式的图像。在opencv中最常用的就是霍夫变换（Hough Lines()）中最常用的就要将其转化为左右两条直线。
霍夫变换的原理：
对于一条直线，我们可以将直线上的点用极坐标来表示出来
[![rbPca4.png](https://s3.ax1x.com/2020/12/29/rbPca4.png)](https://imgchr.com/i/rbPca4)

因此一条直线也就被转换为θ角度内(r,θ)的集合，也被称为霍夫空间。

整条直线也就被映射为以θ为横坐标，r为纵坐标的曲线，同一条直线上的点就会表现为多个曲线的交点。霍夫变换，就是根据相交曲线的数量，来判断是否是直线，假如只有3条曲线相交，它可能是图像恰好不同位置的交点而已（其实也不一定，因为在进行canny的边缘检测后，我们又对区域进行截取，已经能保证区域中95%以上都是车道线内容，当可能水平直线中，左右车道线中有部分点处于同一直线，就会导致结果中出现垂直的变换结果）因此对于参数threshold我们还是设置的多一点比较好。（也不能太多，不然，对于虚线情况下的车道线说不定数量也不够，这样就少线了，可能导致之后的拟合出现误差）
* 裁剪后的车道线
[![rbPLid.png](https://s3.ax1x.com/2020/12/29/rbPLid.png)](https://imgchr.com/i/rbPLid)
经过霍夫变换，会返回一个（21，1，4）的数组，里面存储的都是笛卡尔坐标系中的xy值，之后就要将每个点进行分类，根据k值的正负号来判断这个点属于左车道线还是右车道线，将其分为right_line和left_line后，我们将它们进行最小二乘的拟合，这样就可以保证虚线形式下的车道线检测也是一条直线，根据所有线中的最大值来固定能拟合出的车道线的长度。
* 画出对应车道线
[![rbiZQ0.png](https://s3.ax1x.com/2020/12/29/rbiZQ0.png)](https://imgchr.com/i/rbiZQ0)

接下来就是只要将该车道线绘制到原图像上即可，最终的效果图如下，我们可以清楚的看到我们找到车道线与实际车道线的重合。
[![rbFZhd.png](https://s3.ax1x.com/2020/12/29/rbFZhd.png)](https://imgchr.com/i/rbFZhd)

### 3.5 实现的代码
``` python
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import cv2
%matplotlib inline
 
image = cv2.imread('1.jpg',0)
 
print('This image is:', type(image), 'with dimensions:', image.shape)
import math
 
def grayscale(img):
    """
    将图像处理为灰度图像，因为使用cv2read所以要用BGR进行转换
    
    """
    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
def canny(img, low_threshold, high_threshold):#返回image，边缘部分为255，其余为0
 
    return cv2.Canny(img, low_threshold, high_threshold)
 
def gaussian_blur(img, kernel_size):
 
    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)
 
def region_of_interest(img, vertices):
    mask = np.zeros_like(img)   
    print("mask_shape",mask.shape)
    if len(img.shape) > 2:
        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image
        ignore_mask_color = (255,) * channel_count
    else:
        ignore_mask_color = 255
 
    cv2.fillPoly(mask, vertices, ignore_mask_color)
    
    masked_image = cv2.bitwise_and(img, mask)
    return masked_image
 
def draw_lines(img, lines, color=[255,116,10], thickness=2):
        left_lines_x = []
        left_lines_y = []
        right_lines_x = []
        right_lines_y = []
        line_y_max = 0
        line_y_min = 999
        for line in lines:
            for x1,y1,x2,y2 in line:
                if y1 > line_y_max:
                    line_y_max = y1
                if y2 > line_y_max:
                    line_y_max = y2
                if y1 < line_y_min:
                    line_y_min = y1
                if y2 < line_y_min:
                    line_y_min = y2
                k = (y2 - y1)/(x2 - x1)
                if k < -0.3:
                    left_lines_x.append(x1)
                    left_lines_y.append(y1)
                    left_lines_x.append(x2)
                    left_lines_y.append(y2)
                elif k > 0.3:
 
                    right_lines_x.append(x1)
                    right_lines_y.append(y1)
                    right_lines_x.append(x2)
                    right_lines_y.append(y2)
        #最小二乘直线拟合
        left_line_k, left_line_b = np.polyfit(left_lines_x, left_lines_y, 1)
        right_line_k, right_line_b = np.polyfit(right_lines_x, right_lines_y, 1)
        #根据直线方程和最大、最小的y值反算对应的x
        cv2.line(img,(int((line_y_max - left_line_b)/left_line_k), line_y_max),(int((line_y_min - left_line_b)/left_line_k), line_y_min),color, thickness)
        cv2.line(img,(int((line_y_max - right_line_b)/right_line_k), line_y_max),(int((line_y_min - right_line_b)/right_line_k), line_y_min),color, thickness)
 
def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):
    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)
    print(lines.shape)
    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)
    draw_lines(line_img, lines)
    return line_img
 
 
def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):
 
    return cv2.addWeighted(initial_img, α, img, β, γ)
 
ini_image = cv2.imread("1.jpg")
#plt.imshow(ini_image)
imshape=ini_image.shape
gray=grayscale(ini_image)
#after灰度处理
 
kernel_size=5
blur=gaussian_blur(gray, kernel_size)
 
#after高斯模糊
low_threshold=50
high_threshold=200
edges=canny(blur, low_threshold, high_threshold)
 
vertices=np.array([[(0,imshape[0]),(imshape[1]/2-20, imshape[0]/2+50),
                        (imshape[1]/2+20, imshape[0]/2+50), 
                    (imshape[1],imshape[0]),(0,500),(960,500)]],
                      dtype=np.int32)
 
partial=region_of_interest(edges,vertices)
x=[0,0,460,500,960,960]
y=[540,500,320,320,500,540]
plt.plot(x,y)
plt.imshow(edges)
 
rho=1
theta=np.pi/180
threshold=13
min_line_len=15
max_line_gap=10
lines=hough_lines(partial, rho, theta, threshold, min_line_len, max_line_gap)
 
final=weighted_img(lines,ini_image)
ini_image = cv2.imread("1.jpg")
imshape=ini_image.shape
gray=grayscale(ini_image)
#after灰度处理
 
kernel_size=5
blur=gaussian_blur(gray, kernel_size)
#after高斯模糊
 
 
low_threshold=120
high_threshold=200
edges=canny(blur, low_threshold, high_threshold)
#aftercannoy滤波
vertices=np.array([[(0,imshape[0]),(imshape[1]/2-20, imshape[0]/2+50),  \
                        (imshape[1]/2+20, imshape[0]/2+50), (imshape[1],imshape[0]),(0,500),(960,500)]], \
                      dtype=np.int32)
 
 
partial=region_of_interest(edges,vertices)
 
rho=1
theta=np.pi/180
threshold=13
min_line_len=15
max_line_gap=10
lines=hough_lines(partial, rho, theta, threshold, min_line_len, max_line_gap)
final=weighted_img(lines,ini_image)
cv2.imshow('Final', final)
cv2.waitKey(0)
cv2.destroyAllWindows()
 
```

### 课程设计总结
在本次实验中，主要通过高斯滤波，Canny边缘检测，霍夫变换完成大部分内容，本次实验也只是对单一图片进行识别，同时道路还是直线，就更为的简单，相比于视频流的输入，面对不同路况以及弯曲的车道线，以及将车道线进行透明转换，该实验也只是入门中的入门。通过这次动手也加深了对高斯模糊，高通滤波，Sobel算子，Canny中阈值的变换，霍夫变换笛卡尔坐标与极坐标的转换这些理论进行了各种实践与尝试，上面提到的拓展内容，会在以后继续深入实现（不过这些都在Github上有相应的开源代码）
还有一个问题就是，对于左右两侧的车道线的识别，当无人驾驶的汽车进行变道时，只靠一个摄像头捕捉肯定是不够的，这时候单用这种算法一定会出现错误，应该只能在两侧都捕捉路面信息，与本次实验不同，只是在截取车道线时，不是再选一个正下方类似三角形的形状，二是左（右）侧类似平行四边形的形状。这样就能保证获取周围车道线的信息，为变更车道做准备。

### 课程设计心得
通过这一次的课程设计让我对这门课程有了更透彻的认识，但是车道线检测知识一个入门的检测试验，这个项目只是简单的车道线检测，并没有做进一步的扩展，比如相机的标定，根据车道线的位置判断车辆偏移车道的情况等。在学习代码的过程中不断度阅读他人的博客，给了我极大的帮助，希望之后自己也可以不断分享学习感悟，最后感谢开源。


 



